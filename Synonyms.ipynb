{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from random import randint\n",
    "import nltk.data\n",
    "import re\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "path ='./'\n",
    "dataset = pd.read_csv(path + 'train.csv'.format(1), engine='python')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    144277\n",
      "Name: toxic, dtype: int64\n",
      "1    15294\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "word = 'toxic'\n",
    "print(dataset[word][dataset[word] == 0].value_counts())\n",
    "print(dataset[word][dataset[word] == 1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting joblib\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/51/870b2ec270fc29c5d89f85353da420606a9cb39fba4747127e7c7d7eb25d/joblib-0.11-py2.py3-none-any.whl (176kB)\n",
      "Collecting textblob\n",
      "  Downloading https://files.pythonhosted.org/packages/11/18/7f55c8be6d68ddc4036ffda5382ca51e23a1075987f708b9123712091af1/textblob-0.15.1-py2.py3-none-any.whl (631kB)\n",
      "Requirement already up-to-date: nltk>=3.1 in c:\\python27\\lib\\site-packages (from textblob)\n",
      "Requirement already up-to-date: six in c:\\python27\\lib\\site-packages (from nltk>=3.1->textblob)\n",
      "Installing collected packages: joblib, textblob\n",
      "Successfully installed joblib-0.11 textblob-0.15.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 10.0.0 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib textblob -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from textblob import TextBlob\n",
    "from textblob.translate import NotTranslated\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=dataset[dataset['toxic']==1]\n",
    "ds=ds[['comment_text','toxic']][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "chkr = SpellChecker(\"en_UK\", \"en_US\")\n",
    "\n",
    "def low(x):\n",
    "    # spelling checker\n",
    "    x = re.sub(r'[\\W_]+', ' ', x)\n",
    "    chkr.set_text(x)\n",
    "    for err in chkr:\n",
    "        if len(err.suggest()) > 0:\n",
    "            sug = err.suggest()[0]\n",
    "            err.replace(sug)\n",
    "            x = chkr.get_text()\n",
    "    \n",
    "    return x.lower()\n",
    "\n",
    "\n",
    "ds['comment_text'] = ds['comment_text'].apply(lambda x: low(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_WORD = \"_NAN_\"\n",
    "\n",
    "\n",
    "def translate(comment, language):\n",
    "    if hasattr(comment, \"decode\"):\n",
    "        comment = comment.decode(\"utf-8\")\n",
    "\n",
    "    text = TextBlob(comment)\n",
    "    try:\n",
    "        text = text.translate(to='de')\n",
    "        text = text.translate(to=language)\n",
    "        text = text.translate(to=\"en\")\n",
    "    except NotTranslated:\n",
    "        pass\n",
    "\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6      None\n",
       "12     None\n",
       "16     None\n",
       "42     None\n",
       "43     None\n",
       "44     None\n",
       "51     None\n",
       "55     None\n",
       "56     None\n",
       "58     None\n",
       "59     None\n",
       "65     None\n",
       "79     None\n",
       "86     None\n",
       "105    None\n",
       "151    None\n",
       "159    None\n",
       "168    None\n",
       "176    None\n",
       "181    None\n",
       "201    None\n",
       "206    None\n",
       "211    None\n",
       "218    None\n",
       "231    None\n",
       "238    None\n",
       "268    None\n",
       "278    None\n",
       "286    None\n",
       "295    None\n",
       "       ... \n",
       "415    None\n",
       "423    None\n",
       "429    None\n",
       "437    None\n",
       "439    None\n",
       "442    None\n",
       "451    None\n",
       "476    None\n",
       "497    None\n",
       "503    None\n",
       "519    None\n",
       "520    None\n",
       "521    None\n",
       "529    None\n",
       "579    None\n",
       "582    None\n",
       "590    None\n",
       "600    None\n",
       "602    None\n",
       "604    None\n",
       "608    None\n",
       "610    None\n",
       "632    None\n",
       "638    None\n",
       "641    None\n",
       "642    None\n",
       "643    None\n",
       "655    None\n",
       "665    None\n",
       "679    None\n",
       "Length: 70, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp=ds[[\"comment_text\", \"toxic\"]][0:70]\n",
    "df =ds[[\"comment_text\", \"toxic\"]][0:70].copy()\n",
    "\n",
    "def upsample(comment, label):\n",
    "    global dp\n",
    "    l = ['es', 'fr', 'it']\n",
    "    for language in l:\n",
    "        new_comment = translate(comment, language)\n",
    "        dp=dp.append(pd.Series({\"comment_text\":new_comment,\"toxic\":label}),ignore_index=True)\n",
    "        \n",
    "df.apply(lambda x: upsample(x[\"comment_text\"], x[\"toxic\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\gatto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gatto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#just one time\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial=ds[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cocksucker ahead you peeing about on my work\n",
      " hey what be information_technology talk what cost information_technology an exclusive group of some p taliban world_health_organization be beneficial astatine destroy self appointed purist world_health_organization gang up any one world_health_organization ask them doubt bat their anti social and destructive not contribution at p ask sinuosity to clean astir his behavior than issue maine absurd warn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load a text file if required\n",
    "\n",
    "\n",
    "# Load the pretrained neural net\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "\n",
    "for text in trial[\"comment_text\"]:\n",
    "    output=\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer.tokenize(text)\n",
    "\n",
    "    # Get the list of words from the entire text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Identify the parts of speech\n",
    "    tagged = nltk.pos_tag(words)\n",
    "\n",
    "    for i in range(0,len(words)):\n",
    "        \n",
    "        replacements = []\n",
    "\n",
    "        # Only replace nouns with nouns, vowels with vowels etc.\n",
    "        for syn in wordnet.synsets(words[i]):\n",
    "\n",
    "            # Do not attempt to replace proper nouns or determiners\n",
    "            if tagged[i][1] == 'NNP' or tagged[i][1] == 'DT':\n",
    "                break\n",
    "\n",
    "            # The tokenizer returns strings like NNP, VBP etc\n",
    "            # but the wordnet synonyms has tags like .n.\n",
    "            # So we extract the first character from NNP ie n\n",
    "            # then we check if the dictionary word has a .n. or not \n",
    "            word_type = tagged[i][1][0].lower()\n",
    "            if syn.name().find(\".\"+word_type+\".\"):\n",
    "                # extract the word only\n",
    "                r = syn.name()[0:syn.name().find(\".\")]\n",
    "                replacements.append(r)\n",
    "\n",
    "        if len(replacements) > 0:\n",
    "            # Choose a random replacement\n",
    "            replacement = replacements[randint(0,len(replacements)-1)]\n",
    "            output = output + \" \" + replacement\n",
    "        else:\n",
    "            # If no replacement could be found, then just use the\n",
    "            # original word\n",
    "            output = output + \" \" + words[i]\n",
    "    print output\n",
    "    trial=trial.append(pd.Series({\"comment_text\":output,\"toxic\":1}),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hey what is it talk what is it an exclusive gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cocksucker ahead you peeing about on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hey what be information_technology talk what ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic\n",
       "0       cocksucker before you piss around on my work      1\n",
       "1  hey what is it talk what is it an exclusive gr...      1\n",
       "2       cocksucker ahead you peeing about on my work      1\n",
       "3   hey what be information_technology talk what ...      1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gatto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tok_and_rem(x):\n",
    "    s = x.split()\n",
    "    l = list(s)\n",
    "    for word in s:\n",
    "        if (len(word) <= 2):\n",
    "            l.remove(word)\n",
    "        elif word in stopwords.words('english'):\n",
    "            l.remove(word)\n",
    "    return l\n",
    "\n",
    "dp['comment_text'] = dp['comment_text'].apply(lambda x: tok_and_rem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
