{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GfI4uspYeTmK"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/rr2n17/AdvML.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1714,
     "status": "ok",
     "timestamp": 1524403039064,
     "user": {
      "displayName": "Anton Okhotnikov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111886964614144141367"
     },
     "user_tz": -60
    },
    "id": "DKO2N7kTfQmW",
    "outputId": "f53b1ba8-f1c5-4731-c495-76dab5e9c12b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t    toxic_french_2000.csv  upsampling.ipynb\r\n",
      "obscene_french.csv  toxic_french.csv\t   upsampling_old.ipynb\r\n",
      "test.csv\t    train.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGP2vCLyaiMQ"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "mrOpEu2uWfjI"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install nltk\n",
    "# !apt-get install libenchant1c2a\n",
    "# !pip install pyenchant\n",
    "# !pip install joblib textblob -U\n",
    "# !pip install ipyparallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "LS6HAG0sYkTy"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from random import randint\n",
    "import nltk.data\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import re\n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "from joblib import Parallel, delayed\n",
    "from textblob import TextBlob\n",
    "from textblob.translate import NotTranslated\n",
    "from ipyparallel import Client\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tax-9UqIqo5S"
   },
   "outputs": [],
   "source": [
    "# nltk.download(\"averaged_perceptron_tagger\")\n",
    "# nltk.download(\"wordnet\")\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "05VDJMTzYIvK"
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1782,
     "status": "ok",
     "timestamp": 1524407312996,
     "user": {
      "displayName": "Anton Okhotnikov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111886964614144141367"
     },
     "user_tz": -60
    },
    "id": "nH8hl60SW9VY",
    "outputId": "c55d7b3d-85ba-4453-e819-986df97b2608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./train.csv\"\n",
    "dataset = pd.read_csv(path)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = Client()\n",
    "c.ids[-3:]\n",
    "cc = c[:]\n",
    "cc50 = c[:50]\n",
    "cc100 = c[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @cc.remote(block=True)\n",
    "# def getpid():\n",
    "#     import os\n",
    "#     return os.getpid()\n",
    "# print(getpid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWDnxj8bm_gm"
   },
   "source": [
    "## Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# def timef(func):\n",
    "#     t1 = time.time()\n",
    "#     res = func\n",
    "#     t2 = time.time()\n",
    "#     print(t2 - t1)\n",
    "#     return [res] \n",
    "\n",
    "# @cc.parallel(block=True)\n",
    "# # @timef\n",
    "# def test(lst):\n",
    "#     l = []\n",
    "#     for i in lst:\n",
    "#         l.append(i)\n",
    "#     return len(l)\n",
    "\n",
    "# x = range(10000000)\n",
    "\n",
    "# t1 = time.time()\n",
    "# print(test(x))\n",
    "# t2 = time.time()\n",
    "# print(t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1405, 8)\n"
     ]
    }
   ],
   "source": [
    "toxic = dataset[dataset['identity_hate'] == 1]\n",
    "print(toxic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.99495577812195\n"
     ]
    }
   ],
   "source": [
    "%px import re\n",
    "%px from enchant.checker import SpellChecker\n",
    "\n",
    "# tokenizer = TreebankWordTokenizer()\n",
    "chkr = SpellChecker(\"en_UK\", \"en_US\")\n",
    "\n",
    "@cc50.parallel(block=True)\n",
    "def preprocess(list_of_comments):\n",
    "    \"\"\"\n",
    "    \n",
    "    Replaces words that are written mistakenly with the \n",
    "    closest (enchant.checker.Spellchecker) and turns them to the lowercase then\n",
    "    \n",
    "    External libraries used:\n",
    "    :enchant.SpellChecker: not found words are replaced with the most similar\n",
    "    \n",
    "    IO:\n",
    "    :type comment: str\n",
    "    :rtype: str\n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for comment in list_of_comments:\n",
    "        ## retrieve alphanumeric and underscore \n",
    "        ## words, replace with \" \" if matches\n",
    "        t = type(comment)\n",
    "        comment = re.sub(r'[\\W_]+', \" \", str(comment)).lower()\n",
    "        ## run through checker if the words exist\n",
    "        ## replace words that are not found with a recommended word\n",
    "        chkr = SpellChecker(\"en_UK\", \"en_US\")\n",
    "        chkr.set_text(comment)\n",
    "        for err in chkr:\n",
    "            if err.suggest():\n",
    "                sug = err.suggest()[0] # take the first item from the recommended words\n",
    "                err.replace(sug)\n",
    "        res.append(chkr.get_text())\n",
    "    return res\n",
    "\n",
    "t1 = time.time()\n",
    "toxic = toxic.reset_index(drop=True)\n",
    "toxic['comment_text'] = pd.Series(preprocess(list(toxic['comment_text'])))\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>fb726deec64157bd</td>\n",
       "      <td>lo you re gay you will never know how good it ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>fc3efa2f6f025f6d</td>\n",
       "      <td>oh fuck off the pansy Jew would just whine abo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>fd052883fa6a8697</td>\n",
       "      <td>shalom Semite get the fuck out of here i will ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>fdce660ddcd6d7ca</td>\n",
       "      <td>i think he is a gay fag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>fef4cf7ba0012866</td>\n",
       "      <td>our previous conversation you fucking shit ea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                       comment_text  \\\n",
       "1400  fb726deec64157bd  lo you re gay you will never know how good it ...   \n",
       "1401  fc3efa2f6f025f6d  oh fuck off the pansy Jew would just whine abo...   \n",
       "1402  fd052883fa6a8697  shalom Semite get the fuck out of here i will ...   \n",
       "1403  fdce660ddcd6d7ca                           i think he is a gay fag    \n",
       "1404  fef4cf7ba0012866   our previous conversation you fucking shit ea...   \n",
       "\n",
       "      toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "1400      1             1        1       0       1              1  \n",
       "1401      1             0        1       0       1              1  \n",
       "1402      1             1        1       1       1              1  \n",
       "1403      1             0        0       0       0              1  \n",
       "1404      1             0        1       0       1              1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "y6IngfjUb4aA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.520253658294678\n"
     ]
    }
   ],
   "source": [
    "%px from textblob import TextBlob\n",
    "%px from textblob.translate import NotTranslated\n",
    "\n",
    "@cc100.parallel(block=True)\n",
    "def upsample_via_lang(comments, langs):\n",
    "    \"\"\"\n",
    "    \n",
    "    Upsamples by creating variations of a comment\n",
    "    by translating from English -> German -> French -> English\n",
    "    \n",
    "    :type list_of_comments: list of commentaries of a string type\n",
    "    :rtype: a new variation of commentaries\n",
    "    \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for comment in comments:\n",
    "        if not isinstance(comment, str):\n",
    "            comment = str(comment)\n",
    "        if hasattr(comment, \"decode\"):\n",
    "            comment = comment.decode(\"utf-8\")\n",
    "        text = TextBlob(comment)\n",
    "        try:\n",
    "            text = text.translate(to='de')\n",
    "            text = text.translate(to='fr')\n",
    "            text = text.translate(to=\"en\")\n",
    "            text = re.sub(r'[\\W_]+', ' ', str(text))\n",
    "        except NotTranslated:\n",
    "            pass\n",
    "        res.append(text)\n",
    "    return [re.sub(r'[\\W_]+', ' ', str(text)) for text in res]\n",
    "\n",
    "t1 = time.time()\n",
    "comments = list(toxic['comment_text'])\n",
    "lang = 'fr'\n",
    "langs = [lang for i in range(len(comments))]\n",
    "comments_from_french = pd.Series(upsample_via_lang(comments, langs))\n",
    "t2 = time.time()\n",
    "print(t2 - t1)\n",
    "# x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qQU12mBBnV1M",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pretrained neural net\n",
    "tokenizer = nltk.data.load('../../../nltk_data/tokenizers/punkt/english.pickle')\n",
    "\n",
    "dp = pd.DataFrame()\n",
    "dp[\"fr\"] = comments_from_french\n",
    "\n",
    "for text in dp[\"fr\"]:\n",
    "    text = str(text)\n",
    "    output=\"\"\n",
    "    # Tokenize the text\n",
    "    tokenized = tokenizer.tokenize(text)\n",
    "\n",
    "    # Get the list of words from the entire text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Identify the parts of speech\n",
    "    tagged = nltk.pos_tag(words)\n",
    "\n",
    "    for i in range(0,len(words)):\n",
    "        \n",
    "        replacements = []\n",
    "\n",
    "        # Only replace nouns with nouns, vowels with vowels etc.\n",
    "        for syn in wordnet.synsets(words[i]):\n",
    "\n",
    "            # Do not attempt to replace proper nouns or determiners\n",
    "            if tagged[i][1] == 'NNP' or tagged[i][1] == 'DT':\n",
    "                break\n",
    "\n",
    "            # The tokenizer returns strings like NNP, VBP etc\n",
    "            # but the wordnet synonyms has tags like .n.\n",
    "            # So we extract the first character from NNP ie n\n",
    "            # then we check if the dictionary word has a .n. or not \n",
    "            word_type = tagged[i][1][0].lower()\n",
    "            if syn.name().find(\".\"+word_type+\".\"):\n",
    "                # extract the word only\n",
    "                r = syn.name()[0:syn.name().find(\".\")]\n",
    "                replacements.append(r)\n",
    "\n",
    "        if len(replacements) > 0:\n",
    "            # Choose a random replacement\n",
    "            replacement = replacements[randint(0,len(replacements)-1)]\n",
    "            output = output + \" \" + replacement\n",
    "        else:\n",
    "            # If no replacement could be found, then just use the\n",
    "            # original word\n",
    "            output = output + \" \" + words[i]\n",
    "    \n",
    "    dp = dp.append(pd.Series({\"fr\":output}),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7VeMvBD7n5sY"
   },
   "outputs": [],
   "source": [
    "%px from nltk.corpus import wordnet, stopwords\n",
    "\n",
    "@cc50.parallel(block=True)\n",
    "def tok_and_rem(comments):\n",
    "    res = []\n",
    "    for x in comments:\n",
    "        s = x.split()\n",
    "        l = list(s)\n",
    "        for word in s:\n",
    "            if (len(word) <= 2):\n",
    "                l.remove(word)\n",
    "            elif word in stopwords.words('english'):\n",
    "                l.remove(word)\n",
    "        res.append(l)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1524406980606,
     "user": {
      "displayName": "Anton Okhotnikov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111886964614144141367"
     },
     "user_tz": -60
    },
    "id": "U7oSMCgxn6rq",
    "outputId": "6c52c197-878b-4716-9409-688036902da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2810, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>You embody brave you will never know how dece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>ohio crap the Jew of Thought would have fair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>semitic shalom draw you out of here i will ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>one think helium s a gay fagot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>our previous conversation you fucking denounc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     fr\n",
       "2805   You embody brave you will never know how dece...\n",
       "2806   ohio crap the Jew of Thought would have fair ...\n",
       "2807   semitic shalom draw you out of here i will ki...\n",
       "2808                     one think helium s a gay fagot\n",
       "2809   our previous conversation you fucking denounc..."
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dp.shape)\n",
    "dp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.915174722671509"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "pd.Series(tok_and_rem(list(dp['fr'])))\n",
    "t2 = time.time()\n",
    "t2 - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "YAMSRXhWyCzU"
   },
   "outputs": [],
   "source": [
    "dp.to_csv(\"identity_hate_french_2810.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               7877\n",
       "comment_text     7877\n",
       "toxic            7877\n",
       "severe_toxic     7877\n",
       "obscene          7877\n",
       "threat           7877\n",
       "insult           7877\n",
       "identity_hate    7877\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toxic severe_toxic obscene threat insult identity_hate\n",
    "dataset[dataset[\"insult\"] == 1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "upsampling.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
