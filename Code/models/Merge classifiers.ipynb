{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\apps\\anaconda2\\envs\\env2\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Toxic', 'Severe', 'Obscene', 'Threat', 'Insult', 'Identity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spell_checker32MMp1.csv')\n",
    "df = pd.concat([df, pd.read_csv('spell_checker32MMp2.csv')])\n",
    "df = pd.concat([df, pd.read_csv('spell_checker32MMp3.csv')])\n",
    "df = df.iloc[:, 1:]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "ids = pd.read_csv('test.csv')\n",
    "ids = ids['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05647484,  0.0943086 ,  0.18976713, ...,  0.00348375,\n",
       "         0.00067335, -0.01066972],\n",
       "       [ 0.16755086, -0.11362292, -0.20672155, ..., -0.06140746,\n",
       "        -0.03262367, -0.00359173],\n",
       "       [ 0.09340793, -0.09266319, -0.13996158, ..., -0.0206565 ,\n",
       "         0.01268927, -0.00550548],\n",
       "       ...,\n",
       "       [-0.10872087,  0.00290806,  0.02554503, ..., -0.01376142,\n",
       "        -0.00544102,  0.00915878],\n",
       "       [-0.10625417,  0.0177638 , -0.11193075, ...,  0.01413548,\n",
       "        -0.01402142,  0.00892577],\n",
       "       [ 0.30270611,  0.17246708, -0.01458978, ..., -0.01239552,\n",
       "         0.02174533,  0.01650812]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = df.as_matrix()\n",
    "del df\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the LR classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clfs/LR/'\n",
    "LR = {}\n",
    "for name in names:\n",
    "    filename = \"LR_{name}.sav\".format(name=name)\n",
    "    LR[name] = pickle.load(open(path + filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Toxic': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=1, warm_start=False),\n",
       " 'Severe': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=1, warm_start=False),\n",
       " 'Obscene': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=1, warm_start=False),\n",
       " 'Threat': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=1, warm_start=False),\n",
       " 'Insult': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=1, warm_start=False),\n",
       " 'Identity': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "           penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=1, warm_start=False)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the LDA classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'clfs/LDA/'\n",
    "LDA = {}\n",
    "for name in names:\n",
    "    filename = \"LDA_{name}.sav\".format(name=name)\n",
    "    LDA[name] = pickle.load(open(path + filename, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Toxic': LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001),\n",
       " 'Severe': LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001),\n",
       " 'Obscene': LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001),\n",
       " 'Threat': LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001),\n",
       " 'Insult': LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001),\n",
       " 'Identity': LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "               solver='svd', store_covariance=False, tol=0.0001)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from file\n",
    "path = 'clfs/MLP/'\n",
    "MLP = {}\n",
    "for name in names:\n",
    "    filename = \"MLP_{name}.h5\".format(name=name)\n",
    "    MLP[name] = load_model(path + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Toxic': <keras.models.Sequential at 0x1e998a9fac8>,\n",
       " 'Severe': <keras.models.Sequential at 0x1e9cd373710>,\n",
       " 'Obscene': <keras.models.Sequential at 0x1e998c8eb38>,\n",
       " 'Threat': <keras.models.Sequential at 0x1e998eee7f0>,\n",
       " 'Insult': <keras.models.Sequential at 0x1e9cea13978>,\n",
       " 'Identity': <keras.models.Sequential at 0x1e999650320>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = pd.DataFrame(columns=['id'])\n",
    "dp['id'] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Toxic</th>\n",
       "      <th>Severe</th>\n",
       "      <th>Obscene</th>\n",
       "      <th>Threat</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.903428</td>\n",
       "      <td>0.792703</td>\n",
       "      <td>0.99656</td>\n",
       "      <td>0.982161</td>\n",
       "      <td>0.969188</td>\n",
       "      <td>0.712949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.0359404</td>\n",
       "      <td>0.13601</td>\n",
       "      <td>0.53579</td>\n",
       "      <td>0.0432466</td>\n",
       "      <td>0.0642054</td>\n",
       "      <td>0.437309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.0136301</td>\n",
       "      <td>0.999234</td>\n",
       "      <td>0.49967</td>\n",
       "      <td>0.161457</td>\n",
       "      <td>0.055157</td>\n",
       "      <td>0.202645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.00918823</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>0.111489</td>\n",
       "      <td>0.131479</td>\n",
       "      <td>0.00966507</td>\n",
       "      <td>0.970891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.86128</td>\n",
       "      <td>0.830417</td>\n",
       "      <td>0.779917</td>\n",
       "      <td>0.962902</td>\n",
       "      <td>0.921139</td>\n",
       "      <td>0.984436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>0.68906</td>\n",
       "      <td>0.569941</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>0.984372</td>\n",
       "      <td>0.944233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>0.344618</td>\n",
       "      <td>0.16343</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.926384</td>\n",
       "      <td>0.762595</td>\n",
       "      <td>0.686477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>0.889868</td>\n",
       "      <td>0.657191</td>\n",
       "      <td>0.575847</td>\n",
       "      <td>0.255776</td>\n",
       "      <td>0.620129</td>\n",
       "      <td>0.612536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>0.421598</td>\n",
       "      <td>0.0936823</td>\n",
       "      <td>0.451597</td>\n",
       "      <td>0.0920589</td>\n",
       "      <td>0.388948</td>\n",
       "      <td>0.51862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>0.00631172</td>\n",
       "      <td>0.749616</td>\n",
       "      <td>0.818244</td>\n",
       "      <td>0.0652476</td>\n",
       "      <td>0.175904</td>\n",
       "      <td>0.33605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0002eadc3b301559</td>\n",
       "      <td>0.0448546</td>\n",
       "      <td>0.922759</td>\n",
       "      <td>0.410048</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.0410707</td>\n",
       "      <td>0.81552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0002f87b16116a7f</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.520664</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.998456</td>\n",
       "      <td>0.837737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0003806b11932181</td>\n",
       "      <td>0.942728</td>\n",
       "      <td>0.037746</td>\n",
       "      <td>0.68633</td>\n",
       "      <td>0.985398</td>\n",
       "      <td>0.973274</td>\n",
       "      <td>0.847683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0003e1cccfd5a40a</td>\n",
       "      <td>0.721776</td>\n",
       "      <td>0.997769</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.93365</td>\n",
       "      <td>0.85704</td>\n",
       "      <td>0.00115783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00059ace3e3e9a53</td>\n",
       "      <td>0.231151</td>\n",
       "      <td>0.180272</td>\n",
       "      <td>0.983418</td>\n",
       "      <td>0.873716</td>\n",
       "      <td>0.978097</td>\n",
       "      <td>0.890556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>000634272d0d44eb</td>\n",
       "      <td>0.00167625</td>\n",
       "      <td>0.960924</td>\n",
       "      <td>0.0227061</td>\n",
       "      <td>0.053883</td>\n",
       "      <td>0.0201999</td>\n",
       "      <td>0.945532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>000663aff0fffc80</td>\n",
       "      <td>0.000703258</td>\n",
       "      <td>0.704199</td>\n",
       "      <td>0.00155177</td>\n",
       "      <td>0.0122971</td>\n",
       "      <td>0.000639346</td>\n",
       "      <td>0.0155804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000689dd34e20979</td>\n",
       "      <td>0.0118695</td>\n",
       "      <td>0.965478</td>\n",
       "      <td>0.00325551</td>\n",
       "      <td>0.423599</td>\n",
       "      <td>0.00154994</td>\n",
       "      <td>0.744639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>000834769115370c</td>\n",
       "      <td>0.828741</td>\n",
       "      <td>0.975315</td>\n",
       "      <td>0.792902</td>\n",
       "      <td>0.755403</td>\n",
       "      <td>0.898812</td>\n",
       "      <td>0.709744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>000844b52dee5f3f</td>\n",
       "      <td>0.690746</td>\n",
       "      <td>0.219109</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.993815</td>\n",
       "      <td>0.961205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00084da5d4ead7aa</td>\n",
       "      <td>0.0245651</td>\n",
       "      <td>0.314319</td>\n",
       "      <td>3.12422e-05</td>\n",
       "      <td>0.00794847</td>\n",
       "      <td>0.00016614</td>\n",
       "      <td>0.0212435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00091c35fa9d0465</td>\n",
       "      <td>0.108158</td>\n",
       "      <td>0.611972</td>\n",
       "      <td>0.27809</td>\n",
       "      <td>0.664744</td>\n",
       "      <td>0.0972805</td>\n",
       "      <td>0.962872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>000968ce11f5ee34</td>\n",
       "      <td>0.689682</td>\n",
       "      <td>0.707138</td>\n",
       "      <td>0.933315</td>\n",
       "      <td>0.796866</td>\n",
       "      <td>0.236762</td>\n",
       "      <td>0.564502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0009734200a85047</td>\n",
       "      <td>0.0370742</td>\n",
       "      <td>0.449338</td>\n",
       "      <td>0.390969</td>\n",
       "      <td>0.252559</td>\n",
       "      <td>0.301537</td>\n",
       "      <td>0.0125667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00097b6214686db5</td>\n",
       "      <td>0.164726</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.699215</td>\n",
       "      <td>0.998835</td>\n",
       "      <td>0.945965</td>\n",
       "      <td>0.974962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0009aef4bd9e1697</td>\n",
       "      <td>0.981804</td>\n",
       "      <td>0.852623</td>\n",
       "      <td>0.714415</td>\n",
       "      <td>0.788268</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>0.903881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>000a02d807ae0254</td>\n",
       "      <td>0.985282</td>\n",
       "      <td>0.998683</td>\n",
       "      <td>0.0203063</td>\n",
       "      <td>0.630062</td>\n",
       "      <td>0.00142059</td>\n",
       "      <td>0.921427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>000a6c6d4e89b9bc</td>\n",
       "      <td>0.287132</td>\n",
       "      <td>0.953348</td>\n",
       "      <td>0.692929</td>\n",
       "      <td>0.249826</td>\n",
       "      <td>0.0421083</td>\n",
       "      <td>0.912869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>000bafe2080bba82</td>\n",
       "      <td>0.0668516</td>\n",
       "      <td>0.392474</td>\n",
       "      <td>0.885275</td>\n",
       "      <td>0.631341</td>\n",
       "      <td>0.951536</td>\n",
       "      <td>0.591714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>000bf0a9894b2807</td>\n",
       "      <td>0.996149</td>\n",
       "      <td>0.134132</td>\n",
       "      <td>0.969851</td>\n",
       "      <td>0.675389</td>\n",
       "      <td>0.992868</td>\n",
       "      <td>0.0869527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>001c86f5bceccb32</td>\n",
       "      <td>0.446529</td>\n",
       "      <td>0.077696</td>\n",
       "      <td>0.238436</td>\n",
       "      <td>0.578574</td>\n",
       "      <td>0.801994</td>\n",
       "      <td>0.887032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>001cba5e79b6b91e</td>\n",
       "      <td>0.929729</td>\n",
       "      <td>0.871276</td>\n",
       "      <td>0.981932</td>\n",
       "      <td>0.945773</td>\n",
       "      <td>0.921111</td>\n",
       "      <td>0.839977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>001ceacfd4ffa469</td>\n",
       "      <td>0.767777</td>\n",
       "      <td>0.7732</td>\n",
       "      <td>0.80036</td>\n",
       "      <td>0.675992</td>\n",
       "      <td>0.544116</td>\n",
       "      <td>0.767466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>001ceebc43e65027</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>0.673426</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>0.375132</td>\n",
       "      <td>0.348924</td>\n",
       "      <td>0.531353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>001d2f65ea6f4163</td>\n",
       "      <td>0.999427</td>\n",
       "      <td>0.0819537</td>\n",
       "      <td>0.816776</td>\n",
       "      <td>0.990583</td>\n",
       "      <td>0.994319</td>\n",
       "      <td>0.993817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>001d39c71fce6f78</td>\n",
       "      <td>0.997378</td>\n",
       "      <td>0.00445743</td>\n",
       "      <td>0.967591</td>\n",
       "      <td>0.0197032</td>\n",
       "      <td>0.969069</td>\n",
       "      <td>0.0097327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>001d739c97bc2ae4</td>\n",
       "      <td>0.991796</td>\n",
       "      <td>0.00863508</td>\n",
       "      <td>0.559556</td>\n",
       "      <td>0.038494</td>\n",
       "      <td>0.691413</td>\n",
       "      <td>0.00732422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>001deac5571d5186</td>\n",
       "      <td>0.463611</td>\n",
       "      <td>0.750253</td>\n",
       "      <td>0.691447</td>\n",
       "      <td>0.42432</td>\n",
       "      <td>0.402546</td>\n",
       "      <td>0.457269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>001e131e1a08845a</td>\n",
       "      <td>0.109768</td>\n",
       "      <td>0.997878</td>\n",
       "      <td>0.272688</td>\n",
       "      <td>0.142262</td>\n",
       "      <td>0.393558</td>\n",
       "      <td>0.922465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>001eba8bbe728e54</td>\n",
       "      <td>0.828885</td>\n",
       "      <td>0.340477</td>\n",
       "      <td>0.763463</td>\n",
       "      <td>0.730595</td>\n",
       "      <td>0.960355</td>\n",
       "      <td>0.510869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>001ed6d4be00614b</td>\n",
       "      <td>0.133651</td>\n",
       "      <td>0.0466149</td>\n",
       "      <td>0.0299061</td>\n",
       "      <td>0.119259</td>\n",
       "      <td>0.00612532</td>\n",
       "      <td>0.917565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>001eff4007dbb65b</td>\n",
       "      <td>0.731297</td>\n",
       "      <td>0.697264</td>\n",
       "      <td>0.19202</td>\n",
       "      <td>0.119626</td>\n",
       "      <td>0.0899065</td>\n",
       "      <td>0.458231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>001f1f993acff9a3</td>\n",
       "      <td>0.618255</td>\n",
       "      <td>0.183206</td>\n",
       "      <td>0.22924</td>\n",
       "      <td>0.689946</td>\n",
       "      <td>0.455039</td>\n",
       "      <td>0.311947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0020376025dd8092</td>\n",
       "      <td>0.401643</td>\n",
       "      <td>0.912798</td>\n",
       "      <td>0.0139152</td>\n",
       "      <td>0.838108</td>\n",
       "      <td>0.00523491</td>\n",
       "      <td>0.972784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>002046a2e5669735</td>\n",
       "      <td>0.604581</td>\n",
       "      <td>0.554763</td>\n",
       "      <td>0.249733</td>\n",
       "      <td>0.569601</td>\n",
       "      <td>0.531814</td>\n",
       "      <td>0.686208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>002093eb829e4e1b</td>\n",
       "      <td>0.0166654</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>4.08611e-05</td>\n",
       "      <td>0.857821</td>\n",
       "      <td>2.79831e-05</td>\n",
       "      <td>0.999224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>00209bd924d80a3e</td>\n",
       "      <td>0.0429671</td>\n",
       "      <td>0.674076</td>\n",
       "      <td>0.312128</td>\n",
       "      <td>0.639784</td>\n",
       "      <td>0.0168498</td>\n",
       "      <td>0.664481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0020baa22b95d1b0</td>\n",
       "      <td>0.0267199</td>\n",
       "      <td>0.708585</td>\n",
       "      <td>0.0421272</td>\n",
       "      <td>0.112654</td>\n",
       "      <td>0.0125878</td>\n",
       "      <td>0.517552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0020e1f3fafd4b17</td>\n",
       "      <td>0.255436</td>\n",
       "      <td>0.746187</td>\n",
       "      <td>0.654857</td>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.753725</td>\n",
       "      <td>0.576945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0020f1b79913e7c0</td>\n",
       "      <td>0.0963238</td>\n",
       "      <td>0.567538</td>\n",
       "      <td>0.10794</td>\n",
       "      <td>0.109599</td>\n",
       "      <td>0.0594132</td>\n",
       "      <td>0.566726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0021e57e6b9cb3d9</td>\n",
       "      <td>0.017736</td>\n",
       "      <td>0.98709</td>\n",
       "      <td>0.0294924</td>\n",
       "      <td>0.100644</td>\n",
       "      <td>0.0110547</td>\n",
       "      <td>0.788804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0021f7c457937f18</td>\n",
       "      <td>0.0882544</td>\n",
       "      <td>0.648954</td>\n",
       "      <td>0.702582</td>\n",
       "      <td>0.459225</td>\n",
       "      <td>0.545153</td>\n",
       "      <td>0.605576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>002261b0415c4f9d</td>\n",
       "      <td>0.623001</td>\n",
       "      <td>0.0911897</td>\n",
       "      <td>0.985457</td>\n",
       "      <td>0.979757</td>\n",
       "      <td>0.907369</td>\n",
       "      <td>0.6909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0023317d123b6fcb</td>\n",
       "      <td>0.00495501</td>\n",
       "      <td>0.0088408</td>\n",
       "      <td>0.54673</td>\n",
       "      <td>0.0456129</td>\n",
       "      <td>0.924083</td>\n",
       "      <td>0.0172971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>00234e493cedb3e1</td>\n",
       "      <td>0.951018</td>\n",
       "      <td>0.981797</td>\n",
       "      <td>0.136086</td>\n",
       "      <td>0.669713</td>\n",
       "      <td>0.0816874</td>\n",
       "      <td>0.990945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0023f3f84f353bce</td>\n",
       "      <td>0.315013</td>\n",
       "      <td>0.477253</td>\n",
       "      <td>0.231444</td>\n",
       "      <td>0.422971</td>\n",
       "      <td>0.268123</td>\n",
       "      <td>0.0212485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>002586bdf3280356</td>\n",
       "      <td>0.85442</td>\n",
       "      <td>0.564162</td>\n",
       "      <td>0.743136</td>\n",
       "      <td>0.435948</td>\n",
       "      <td>0.853313</td>\n",
       "      <td>0.555228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0025a91b6955f1a5</td>\n",
       "      <td>0.997896</td>\n",
       "      <td>0.418601</td>\n",
       "      <td>0.878427</td>\n",
       "      <td>0.231824</td>\n",
       "      <td>0.987939</td>\n",
       "      <td>0.0256242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0025c49d87d9a18f</td>\n",
       "      <td>0.955816</td>\n",
       "      <td>0.439996</td>\n",
       "      <td>0.811635</td>\n",
       "      <td>0.563676</td>\n",
       "      <td>0.97903</td>\n",
       "      <td>0.38606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>00260d8dfcc29827</td>\n",
       "      <td>0.0163502</td>\n",
       "      <td>0.788315</td>\n",
       "      <td>0.330121</td>\n",
       "      <td>0.256705</td>\n",
       "      <td>0.00216237</td>\n",
       "      <td>0.127947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id        Toxic      Severe      Obscene      Threat  \\\n",
       "0   00001cee341fdb12     0.903428    0.792703      0.99656    0.982161   \n",
       "1   0000247867823ef7    0.0359404     0.13601      0.53579   0.0432466   \n",
       "2   00013b17ad220c46    0.0136301    0.999234      0.49967    0.161457   \n",
       "3   00017563c3f7919a   0.00918823      0.9829     0.111489    0.131479   \n",
       "4   00017695ad8997eb      0.86128    0.830417     0.779917    0.962902   \n",
       "5   0001ea8717f6de06      0.68906    0.569941     0.999969    0.999896   \n",
       "6   00024115d4cbde0f     0.344618     0.16343       0.8963    0.926384   \n",
       "7   000247e83dcc1211     0.889868    0.657191     0.575847    0.255776   \n",
       "8   00025358d4737918     0.421598   0.0936823     0.451597   0.0920589   \n",
       "9   00026d1092fe71cc   0.00631172    0.749616     0.818244   0.0652476   \n",
       "10  0002eadc3b301559    0.0448546    0.922759     0.410048    0.106825   \n",
       "11  0002f87b16116a7f     0.999438    0.520664     0.999936    0.999351   \n",
       "12  0003806b11932181     0.942728    0.037746      0.68633    0.985398   \n",
       "13  0003e1cccfd5a40a     0.721776    0.997769     0.999999     0.93365   \n",
       "14  00059ace3e3e9a53     0.231151    0.180272     0.983418    0.873716   \n",
       "15  000634272d0d44eb   0.00167625    0.960924    0.0227061    0.053883   \n",
       "16  000663aff0fffc80  0.000703258    0.704199   0.00155177   0.0122971   \n",
       "17  000689dd34e20979    0.0118695    0.965478   0.00325551    0.423599   \n",
       "18  000834769115370c     0.828741    0.975315     0.792902    0.755403   \n",
       "19  000844b52dee5f3f     0.690746    0.219109            1    0.999999   \n",
       "20  00084da5d4ead7aa    0.0245651    0.314319  3.12422e-05  0.00794847   \n",
       "21  00091c35fa9d0465     0.108158    0.611972      0.27809    0.664744   \n",
       "22  000968ce11f5ee34     0.689682    0.707138     0.933315    0.796866   \n",
       "23  0009734200a85047    0.0370742    0.449338     0.390969    0.252559   \n",
       "24  00097b6214686db5     0.164726    0.013659     0.699215    0.998835   \n",
       "25  0009aef4bd9e1697     0.981804    0.852623     0.714415    0.788268   \n",
       "26  000a02d807ae0254     0.985282    0.998683    0.0203063    0.630062   \n",
       "27  000a6c6d4e89b9bc     0.287132    0.953348     0.692929    0.249826   \n",
       "28  000bafe2080bba82    0.0668516    0.392474     0.885275    0.631341   \n",
       "29  000bf0a9894b2807     0.996149    0.134132     0.969851    0.675389   \n",
       "..               ...          ...         ...          ...         ...   \n",
       "70  001c86f5bceccb32     0.446529    0.077696     0.238436    0.578574   \n",
       "71  001cba5e79b6b91e     0.929729    0.871276     0.981932    0.945773   \n",
       "72  001ceacfd4ffa469     0.767777      0.7732      0.80036    0.675992   \n",
       "73  001ceebc43e65027     0.011554    0.673426     0.175502    0.375132   \n",
       "74  001d2f65ea6f4163     0.999427   0.0819537     0.816776    0.990583   \n",
       "75  001d39c71fce6f78     0.997378  0.00445743     0.967591   0.0197032   \n",
       "76  001d739c97bc2ae4     0.991796  0.00863508     0.559556    0.038494   \n",
       "77  001deac5571d5186     0.463611    0.750253     0.691447     0.42432   \n",
       "78  001e131e1a08845a     0.109768    0.997878     0.272688    0.142262   \n",
       "79  001eba8bbe728e54     0.828885    0.340477     0.763463    0.730595   \n",
       "80  001ed6d4be00614b     0.133651   0.0466149    0.0299061    0.119259   \n",
       "81  001eff4007dbb65b     0.731297    0.697264      0.19202    0.119626   \n",
       "82  001f1f993acff9a3     0.618255    0.183206      0.22924    0.689946   \n",
       "83  0020376025dd8092     0.401643    0.912798    0.0139152    0.838108   \n",
       "84  002046a2e5669735     0.604581    0.554763     0.249733    0.569601   \n",
       "85  002093eb829e4e1b    0.0166654     0.99982  4.08611e-05    0.857821   \n",
       "86  00209bd924d80a3e    0.0429671    0.674076     0.312128    0.639784   \n",
       "87  0020baa22b95d1b0    0.0267199    0.708585    0.0421272    0.112654   \n",
       "88  0020e1f3fafd4b17     0.255436    0.746187     0.654857    0.455251   \n",
       "89  0020f1b79913e7c0    0.0963238    0.567538      0.10794    0.109599   \n",
       "90  0021e57e6b9cb3d9     0.017736     0.98709    0.0294924    0.100644   \n",
       "91  0021f7c457937f18    0.0882544    0.648954     0.702582    0.459225   \n",
       "92  002261b0415c4f9d     0.623001   0.0911897     0.985457    0.979757   \n",
       "93  0023317d123b6fcb   0.00495501   0.0088408      0.54673   0.0456129   \n",
       "94  00234e493cedb3e1     0.951018    0.981797     0.136086    0.669713   \n",
       "95  0023f3f84f353bce     0.315013    0.477253     0.231444    0.422971   \n",
       "96  002586bdf3280356      0.85442    0.564162     0.743136    0.435948   \n",
       "97  0025a91b6955f1a5     0.997896    0.418601     0.878427    0.231824   \n",
       "98  0025c49d87d9a18f     0.955816    0.439996     0.811635    0.563676   \n",
       "99  00260d8dfcc29827    0.0163502    0.788315     0.330121    0.256705   \n",
       "\n",
       "         Insult    Identity  \n",
       "0      0.969188    0.712949  \n",
       "1     0.0642054    0.437309  \n",
       "2      0.055157    0.202645  \n",
       "3    0.00966507    0.970891  \n",
       "4      0.921139    0.984436  \n",
       "5      0.984372    0.944233  \n",
       "6      0.762595    0.686477  \n",
       "7      0.620129    0.612536  \n",
       "8      0.388948     0.51862  \n",
       "9      0.175904     0.33605  \n",
       "10    0.0410707     0.81552  \n",
       "11     0.998456    0.837737  \n",
       "12     0.973274    0.847683  \n",
       "13      0.85704  0.00115783  \n",
       "14     0.978097    0.890556  \n",
       "15    0.0201999    0.945532  \n",
       "16  0.000639346   0.0155804  \n",
       "17   0.00154994    0.744639  \n",
       "18     0.898812    0.709744  \n",
       "19     0.993815    0.961205  \n",
       "20   0.00016614   0.0212435  \n",
       "21    0.0972805    0.962872  \n",
       "22     0.236762    0.564502  \n",
       "23     0.301537   0.0125667  \n",
       "24     0.945965    0.974962  \n",
       "25     0.948087    0.903881  \n",
       "26   0.00142059    0.921427  \n",
       "27    0.0421083    0.912869  \n",
       "28     0.951536    0.591714  \n",
       "29     0.992868   0.0869527  \n",
       "..          ...         ...  \n",
       "70     0.801994    0.887032  \n",
       "71     0.921111    0.839977  \n",
       "72     0.544116    0.767466  \n",
       "73     0.348924    0.531353  \n",
       "74     0.994319    0.993817  \n",
       "75     0.969069   0.0097327  \n",
       "76     0.691413  0.00732422  \n",
       "77     0.402546    0.457269  \n",
       "78     0.393558    0.922465  \n",
       "79     0.960355    0.510869  \n",
       "80   0.00612532    0.917565  \n",
       "81    0.0899065    0.458231  \n",
       "82     0.455039    0.311947  \n",
       "83   0.00523491    0.972784  \n",
       "84     0.531814    0.686208  \n",
       "85  2.79831e-05    0.999224  \n",
       "86    0.0168498    0.664481  \n",
       "87    0.0125878    0.517552  \n",
       "88     0.753725    0.576945  \n",
       "89    0.0594132    0.566726  \n",
       "90    0.0110547    0.788804  \n",
       "91     0.545153    0.605576  \n",
       "92     0.907369      0.6909  \n",
       "93     0.924083   0.0172971  \n",
       "94    0.0816874    0.990945  \n",
       "95     0.268123   0.0212485  \n",
       "96     0.853313    0.555228  \n",
       "97     0.987939   0.0256242  \n",
       "98      0.97903     0.38606  \n",
       "99   0.00216237    0.127947  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = pd.DataFrame(columns=['id', 'Toxic', 'Severe', 'Obscene', 'Threat', 'Insult', 'Identity'])\n",
    "dm['id'] = ids\n",
    "\n",
    "def classify_comment(matrix):\n",
    "    global dm\n",
    "    for i, row in enumerate(matrix):\n",
    "        row = np.atleast_2d(row)\n",
    "        for name in names:\n",
    "            dm[name].iloc[i] = ((MLP[name].predict(row) + LR[name].predict_proba(row)[0, 1] + LDA[name].predict_proba(row)[0, 1]) / 3.0)[0][0]\n",
    "#             print('MLP output', MLP[name].predict(row))\n",
    "#             print('LR output', LR[name].predict_proba(row))\n",
    "#             print('LDA output', LDA[name].predict_proba(row))\n",
    "\n",
    "def classify(vector):\n",
    "    print(vector)\n",
    "    \n",
    "classify_comment(xx[:100, :])\n",
    "dm.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 1000)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# toxic\n",
    "tmp_labels = ['Toxic', 'Severe', 'Obscene', 'Threat', 'Insult', 'Identity']\n",
    "lables = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "classifiers = {lables[idx]:[MLP[labe], LDA[labe], LR[labe]] for idx, labe in enumerate(tmp_labels)}\n",
    "ignored_models = [0, 2]\n",
    "\n",
    "final_table = dp\n",
    "for i, label in enumerate(lables):\n",
    "    dp1 = dp[:100]\n",
    "    label_classifiers = classifiers[label]\n",
    "    c = 0\n",
    "    for idx, classifer in enumerate(label_classifiers):\n",
    "        if idx in ignored_models:\n",
    "            continue\n",
    "        c += 1\n",
    "        if idx == 0:\n",
    "            dp1 = pd.concat([dp1, pd.DataFrame(classifer.predict(xx))], axis=1)\n",
    "        else:\n",
    "            dp1 = pd.concat([dp1, pd.DataFrame(classifer.predict_proba(xx)[:, 1])], axis=1)\n",
    "    dp1[label] = dp1.iloc[:, 1:].sum(axis=1) / c\n",
    "    final_table = pd.concat([final_table, dp1[label]], axis=1)\n",
    "final_table.to_csv(\"final_fisher_lda.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 7)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1000)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xx[:10, :].shape)\n",
    "classify_comment(xx[:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dp.to_csv('solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
