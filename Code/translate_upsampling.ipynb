{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.tokenize.punkt import PunktWordTokenizer\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import FastText\n",
    "import re\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show, figure\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.manifold        \n",
    "import enchant\n",
    "from enchant.checker import SpellChecker\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "path ='./'\n",
    "dataset = pd.read_csv(path + 'train.csv'.format(1), engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    144277\n",
      "Name: toxic, dtype: int64\n",
      "1    15294\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "word = 'toxic'\n",
    "print(dataset[word][dataset[word] == 0].value_counts())\n",
    "print(dataset[word][dataset[word] == 1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137646"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15294*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "dataset_majority = dataset[dataset.toxic == 0]\n",
    "dataset_minority = dataset[dataset.toxic == 1]\n",
    " \n",
    "# # Upsample minority class\n",
    "# dataset_minority_upsampled = resample(dataset_minority, \n",
    "#                                  replace = True,  # sample with replacement\n",
    "#                                  n_samples = 144277,   # to match majority class\n",
    "#                                  random_state = 123) # reproducible results\n",
    " \n",
    "# # Combine majority class with upsampled minority class\n",
    "# dataset_upsampled = pd.concat([dataset_majority, dataset_minority_upsampled])\n",
    " \n",
    "# # Display new class counts\n",
    "# dataset_upsampled.toxic.value_counts()\n",
    "\n",
    "# Downsample majority class\n",
    "dataset_majority_downsampled = resample(dataset_majority, replace = True, n_samples = len(dataset_minority),\n",
    "                                        random_state = 123)\n",
    "\n",
    "# Combine two classes\n",
    "dataset_ds = pd.concat([dataset_minority, dataset_majority_downsampled])\n",
    "\n",
    "# Shuffle dataset\n",
    "dataset_ds = dataset_ds.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=dataset[dataset['toxic']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install joblib textblob -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from textblob import TextBlob\n",
    "from textblob.translate import NotTranslated\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAN_WORD = \"_NAN_\"\n",
    "\n",
    "\n",
    "def translate(comment, language):\n",
    "    if hasattr(comment, \"decode\"):\n",
    "        comment = comment.decode(\"utf-8\")\n",
    "\n",
    "    text = TextBlob(comment)\n",
    "    try:\n",
    "        text = text.translate(to='de')\n",
    "        text = text.translate(to=language)\n",
    "        text = text.translate(to=\"en\")\n",
    "    except NotTranslated:\n",
    "        pass\n",
    "\n",
    "    return str(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6      None\n",
       "12     None\n",
       "16     None\n",
       "42     None\n",
       "43     None\n",
       "44     None\n",
       "51     None\n",
       "55     None\n",
       "56     None\n",
       "58     None\n",
       "59     None\n",
       "65     None\n",
       "79     None\n",
       "86     None\n",
       "105    None\n",
       "151    None\n",
       "159    None\n",
       "168    None\n",
       "176    None\n",
       "181    None\n",
       "201    None\n",
       "206    None\n",
       "211    None\n",
       "218    None\n",
       "231    None\n",
       "238    None\n",
       "268    None\n",
       "278    None\n",
       "286    None\n",
       "295    None\n",
       "       ... \n",
       "687    None\n",
       "698    None\n",
       "700    None\n",
       "718    None\n",
       "722    None\n",
       "726    None\n",
       "730    None\n",
       "732    None\n",
       "737    None\n",
       "746    None\n",
       "756    None\n",
       "761    None\n",
       "802    None\n",
       "806    None\n",
       "807    None\n",
       "815    None\n",
       "817    None\n",
       "827    None\n",
       "830    None\n",
       "852    None\n",
       "853    None\n",
       "877    None\n",
       "884    None\n",
       "887    None\n",
       "888    None\n",
       "925    None\n",
       "931    None\n",
       "934    None\n",
       "952    None\n",
       "957    None\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp=ds[[\"comment_text\", \"toxic\"]][0:100]\n",
    "df = ds[[\"comment_text\", \"toxic\"]][0:100].copy()\n",
    "\n",
    "def upsample(comment, label):\n",
    "    global dp\n",
    "    l = ['es', 'fr', 'it']\n",
    "    for language in l:\n",
    "        new_comment = translate(comment, language)\n",
    "        dp=dp.append(pd.Series({\"comment_text\":new_comment,\"toxic\":label}),ignore_index=True)\n",
    "        \n",
    "\n",
    "df.apply(lambda x: upsample(x[\"comment_text\"], x[\"toxic\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm Sorry \\n\\nI'm sorry I screwed around with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stupid peace of shit stop deleting my stuff as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>=Tony Sidaway is obviously a fistfuckee. He lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>My Band Page's deletion. You thought I was gon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Why can't you believe how fat Artie is? Did yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All of my edits are good.  Cunts like you who ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hi! I am back again!\\nLast warning!\\nStop undo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Would you both shut up, you don't run wikipedi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A pair of jew-hating weiner nazi schmucks.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>\"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>\"\\n\\nUNBLOCK ME OR I'LL GET MY LAWYERS ON TO Y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>You should be fired, you're a moronic wimp who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I think that your a Fagget get a oife and burn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>you are a stupid fuck \\n\\nand your mother's cu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Your blatant POV pushing \\n\\nNeither of you gu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Give me a permanat block raseac....!!! remembe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fuck you, block me, you faggot pussy!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Kill all niggers. \\n\\nI have hard, that others...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Burn Deck \\n\\nIf that'd guy's burn deck is lik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>u r a tw@ fuck off u gay boy.U r smelly.Fuck u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Atheism is full of bias shit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hey why you are spreading misconceptions and t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\"\\n\\nAnd you are? Let me know when you've craw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>this user is such a worthless goddamn faggot f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Pub\\n\\nYour sad shit I will restore my edition...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>bar\\n\\nYou're sad. I will restore my assembly ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>videogame\\n\\nFor the love of God, when I see t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>video game\\n\\nFor the sake of God, when I see ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>He likes Muhamad Ali's ass and Kelly has a hug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>He loves the ass of Muhamad Ali and Kelly has ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Just shut up and stay closed. Do not work anymore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Shut up and stay closed. Does not work anymore</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>PD Are you a / b / late?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>PS Are you a / b / late?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Ohhh, I'm sorry, did I hurt your little feelin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Ohhh I'm sorry, did I hurt your feelings?\\n\\nL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Piss off, basura mortal!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Emmerde you, deadly foam !!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>\"\\n\\nI take an error!\\n\\nI find it very offens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>\"\\n\\nI take a mistake!\\n\\nI find it very insul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Gay son of a bitch, I know where he lives, I'm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>kind of bastard gay, I know where you live, I'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Ok, Dennis Brown, thanks for telling me that I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Ok, Dennis Brown, thank you for telling me tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Wikipedia is full of weights. Who takes money ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Wikipedia is full of dumbbells. Who takes the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Why change SOMALI PEOPLE WIKI ????????????????...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Why change the SOMALI PEOPLE WIKI ????????????...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>transistor\\n\\nThe transistor side does not hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>transistor\\n\\nThe transistor side has no opera...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>You're an idiot in the class of studies, you s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>You studid sucking you stop me Callin ok he is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>FisherQueen, could I stop tracking each step a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>FisherQueen, would you please stop tracking ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comment_text  toxic\n",
       "0         COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "1    Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "2    Bye! \\n\\nDon't look, come or think of comming ...      1\n",
       "3    You are gay or antisemmitian? \\n\\nArchangel WH...      1\n",
       "4             FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1\n",
       "5    I'm Sorry \\n\\nI'm sorry I screwed around with ...      1\n",
       "6    GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK T...      1\n",
       "7    Stupid peace of shit stop deleting my stuff as...      1\n",
       "8    =Tony Sidaway is obviously a fistfuckee. He lo...      1\n",
       "9    My Band Page's deletion. You thought I was gon...      1\n",
       "10   Why can't you believe how fat Artie is? Did yo...      1\n",
       "11   All of my edits are good.  Cunts like you who ...      1\n",
       "12   Hi! I am back again!\\nLast warning!\\nStop undo...      1\n",
       "13   Would you both shut up, you don't run wikipedi...      1\n",
       "14          A pair of jew-hating weiner nazi schmucks.      1\n",
       "15   \"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS ...      1\n",
       "16   \"\\n\\nUNBLOCK ME OR I'LL GET MY LAWYERS ON TO Y...      1\n",
       "17   You should be fired, you're a moronic wimp who...      1\n",
       "18   I think that your a Fagget get a oife and burn...      1\n",
       "19   you are a stupid fuck \\n\\nand your mother's cu...      1\n",
       "20   Your blatant POV pushing \\n\\nNeither of you gu...      1\n",
       "21   Give me a permanat block raseac....!!! remembe...      1\n",
       "22               Fuck you, block me, you faggot pussy!      1\n",
       "23   Kill all niggers. \\n\\nI have hard, that others...      1\n",
       "24   Burn Deck \\n\\nIf that'd guy's burn deck is lik...      1\n",
       "25   u r a tw@ fuck off u gay boy.U r smelly.Fuck u...      1\n",
       "26                        Atheism is full of bias shit      1\n",
       "27   Hey why you are spreading misconceptions and t...      1\n",
       "28   \"\\n\\nAnd you are? Let me know when you've craw...      1\n",
       "29   this user is such a worthless goddamn faggot f...      1\n",
       "..                                                 ...    ...\n",
       "270  Pub\\n\\nYour sad shit I will restore my edition...      1\n",
       "271  bar\\n\\nYou're sad. I will restore my assembly ...      1\n",
       "272  videogame\\n\\nFor the love of God, when I see t...      1\n",
       "273  video game\\n\\nFor the sake of God, when I see ...      1\n",
       "274  He likes Muhamad Ali's ass and Kelly has a hug...      1\n",
       "275  He loves the ass of Muhamad Ali and Kelly has ...      1\n",
       "276  Just shut up and stay closed. Do not work anymore      1\n",
       "277     Shut up and stay closed. Does not work anymore      1\n",
       "278                           PD Are you a / b / late?      1\n",
       "279                           PS Are you a / b / late?      1\n",
       "280  Ohhh, I'm sorry, did I hurt your little feelin...      1\n",
       "281  Ohhh I'm sorry, did I hurt your feelings?\\n\\nL...      1\n",
       "282                           Piss off, basura mortal!      1\n",
       "283                       Emmerde you, deadly foam !!!      1\n",
       "284  \"\\n\\nI take an error!\\n\\nI find it very offens...      1\n",
       "285  \"\\n\\nI take a mistake!\\n\\nI find it very insul...      1\n",
       "286  Gay son of a bitch, I know where he lives, I'm...      1\n",
       "287  kind of bastard gay, I know where you live, I'...      1\n",
       "288  Ok, Dennis Brown, thanks for telling me that I...      1\n",
       "289  Ok, Dennis Brown, thank you for telling me tha...      1\n",
       "290  Wikipedia is full of weights. Who takes money ...      1\n",
       "291  Wikipedia is full of dumbbells. Who takes the ...      1\n",
       "292  Why change SOMALI PEOPLE WIKI ????????????????...      1\n",
       "293  Why change the SOMALI PEOPLE WIKI ????????????...      1\n",
       "294  transistor\\n\\nThe transistor side does not hav...      1\n",
       "295  transistor\\n\\nThe transistor side has no opera...      1\n",
       "296  You're an idiot in the class of studies, you s...      1\n",
       "297  You studid sucking you stop me Callin ok he is...      1\n",
       "298  FisherQueen, could I stop tracking each step a...      1\n",
       "299  FisherQueen, would you please stop tracking ea...      1\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "# print(tokenizer.tokenize(dataset_ds['comment_text'].iloc[0]))\n",
    "chkr = SpellChecker(\"en_UK\", \"en_US\")\n",
    "\n",
    "def low(x):\n",
    "#     x = x.decode('utf-8')\n",
    "#     if type(x) != unicode:\n",
    "#         x = unicode(x)\n",
    "    # remove numbers\n",
    "#     filter(lambda x: x.isalpha(), x)\n",
    "#     x = re.sub(r'[^\\w]', ' ', x)\n",
    "\n",
    "    # spelling checker\n",
    "    x = re.sub(r'[\\W_]+', ' ', x)\n",
    "    chkr.set_text(x)\n",
    "    for err in chkr:\n",
    "#         print(err.suggest())\n",
    "        if len(err.suggest()) > 0:\n",
    "            sug = err.suggest()[0]\n",
    "            err.replace(sug)\n",
    "            x = chkr.get_text()\n",
    "    \n",
    "    return x.lower()\n",
    "\n",
    "def tok_and_rem(x):\n",
    "#     if type(x) != unicode:\n",
    "#         x = unicode(x)\n",
    "#     s = word_tokenize(x)\n",
    "    s = x.split()\n",
    "    l = list(s)\n",
    "    for word in s:\n",
    "        if (len(word) <= 2):\n",
    "            l.remove(word)\n",
    "        elif word in stopwords.words('english'):\n",
    "            l.remove(word)\n",
    "    return l\n",
    "\n",
    "# to lowercase and remove special characters\n",
    "# dataset_ds['comment_text'] = dataset_ds['comment_text'].apply(lambda x: low(x))\n",
    "dp['comment_text'] = dp['comment_text'].apply(lambda x: low(x))\n",
    "\n",
    "# tokenize and remove stopwords\n",
    "dp['comment_text'] = dp['comment_text'].apply(lambda x: tok_and_rem(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hey', 'talk', 'exclusive', 'group', 'tali', 'bans', 'good', 'destroying', 'self', 'appointed', 'purist', 'gang', 'one', 'asks', 'questions', 'abet', 'anti', 'social', 'destructive', 'non', 'contribution', 'ask', 'sottish', 'clean', 'behavior', 'issue', 'nonsensical', 'warnings']\n",
      "['hey', 'talk', 'exclusive', 'group', 'taliban', 'good', 'destroying', 'destructive', 'self', 'proclaimed', 'purists', 'anyone', 'provides', 'questions', 'antisocial', 'destroy', 'understand', 'contribution', 'ask', 'sottish', 'clean', 'behavior', 'instead', 'warning', 'pointless']\n",
      "['hey', 'speak', 'exclusive', 'group', 'taliban', 'good', 'destroying', 'destructive', 'self', 'proclaimed', 'purists', 'anybody', 'provides', 'questions', 'antisocial', 'destruction', 'contribution', 'understand', 'ask', 'sottish', 'purify', 'behavior', 'instead', 'giving', 'unnecessary', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "print(dp[\"comment_text\"].iloc[1])\n",
    "print(dp[\"comment_text\"].iloc[102])\n",
    "print(dp[\"comment_text\"].iloc[103])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[(dataset[\"severe_toxic\"] == 1) & (dataset[\"toxic\"] == 1)].count())\n",
    "print(dataset[dataset[\"severe_toxic\"] == 1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\"Script for extending train dataset\")\n",
    "parser.add_argument(\"train_file_path\")\n",
    "parser.add_argument(\"--languages\", nargs=\"+\", default=[\"es\", \"de\", \"fr\"])\n",
    "parser.add_argument(\"--thread-count\", type=int, default=300)\n",
    "parser.add_argument(\"--result-path\", default=\"extended_data\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "train_data = pd.read_csv(args.train_file_path)\n",
    "comments_list = train_data[\"comment_text\"].fillna(NAN_WORD).values\n",
    "\n",
    "if not os.path.exists(args.result_path):\n",
    "    os.mkdir(args.result_path)\n",
    "\n",
    "parallel = Parallel(args.thread_count, backend=\"threading\", verbose=5)\n",
    "for language in args.languages:\n",
    "#     print('Translate comments using \"{0}\" language'.format(language))\n",
    "    translated_data = parallel(delayed(translate)(comment, language) for comment in comments_list)\n",
    "    train_data[\"comment_text\"] = translated_data\n",
    "    print(train_data.head())\n",
    "\n",
    "#     result_path = os.path.join(args.result_path, \"train_\" + language + \".csv\")\n",
    "# train_data.to_csv(result_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
