{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c67ab1338112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import show, figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gatto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\gatto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Punctuation and Tokenizer module\n",
    "nltk.download('punkt')\n",
    "# The Gutenberg dataset. A set of 18 books we can used\n",
    "# to train upon.\n",
    "nltk.download('gutenberg')\n",
    "from nltk.corpus import gutenberg as dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path ='./'\n",
    "dataset=pd.read_csv(path + 'train.csv'.format(1))\n",
    "dataset.head()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         None\n",
       "1         None\n",
       "2         None\n",
       "3         None\n",
       "4         None\n",
       "5         None\n",
       "6         None\n",
       "7         None\n",
       "8         None\n",
       "9         None\n",
       "10        None\n",
       "11        None\n",
       "12        None\n",
       "13        None\n",
       "14        None\n",
       "15        None\n",
       "16        None\n",
       "17        None\n",
       "18        None\n",
       "19        None\n",
       "20        None\n",
       "21        None\n",
       "22        None\n",
       "23        None\n",
       "24        None\n",
       "25        None\n",
       "26        None\n",
       "27        None\n",
       "28        None\n",
       "29        None\n",
       "          ... \n",
       "159541    None\n",
       "159542    None\n",
       "159543    None\n",
       "159544    None\n",
       "159545    None\n",
       "159546    None\n",
       "159547    None\n",
       "159548    None\n",
       "159549    None\n",
       "159550    None\n",
       "159551    None\n",
       "159552    None\n",
       "159553    None\n",
       "159554    None\n",
       "159555    None\n",
       "159556    None\n",
       "159557    None\n",
       "159558    None\n",
       "159559    None\n",
       "159560    None\n",
       "159561    None\n",
       "159562    None\n",
       "159563    None\n",
       "159564    None\n",
       "159565    None\n",
       "159566    None\n",
       "159567    None\n",
       "159568    None\n",
       "159569    None\n",
       "159570    None\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = str()\n",
    "\n",
    "def concat(x):\n",
    "    global comments\n",
    "    comments = comments + x\n",
    "\n",
    "\n",
    "dataset['comment_text'].apply(lambda x: concat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Explanation\\nWhy the edits made under my usern...\n",
       "1         D'aww! He matches this background colour I'm s...\n",
       "2         Hey man, I'm really not trying to edit war. It...\n",
       "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4         You, sir, are my hero. Any chance you remember...\n",
       "5         \"\\n\\nCongratulations from me as well, use the ...\n",
       "6              COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
       "7         Your vandalism to the Matt Shirvington article...\n",
       "8         Sorry if the word 'nonsense' was offensive to ...\n",
       "9         alignment on this subject and which are contra...\n",
       "10        \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...\n",
       "11        bbq \\n\\nbe a man and lets discuss it-maybe ove...\n",
       "12        Hey... what is it..\\n@ | talk .\\nWhat is it......\n",
       "13        Before you start throwing accusations and warn...\n",
       "14        Oh, and the girl above started her arguments w...\n",
       "15        \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...\n",
       "16        Bye! \\n\\nDon't look, come or think of comming ...\n",
       "17         REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski\n",
       "18        The Mitsurugi point made no sense - why not ar...\n",
       "19        Don't mean to bother you \\n\\nI see that you're...\n",
       "20        \"\\n\\n Regarding your recent edits \\n\\nOnce aga...\n",
       "21        \"\\nGood to know. About me, yeah, I'm studying ...\n",
       "22        \"\\n\\n Snowflakes are NOT always symmetrical! \\...\n",
       "23        \"\\n\\n The Signpost: 24 September 2012 \\n\\n Rea...\n",
       "24        \"\\n\\nRe-considering 1st paragraph edit?\\nI don...\n",
       "25        Radial symmetry \\n\\nSeveral now extinct lineag...\n",
       "26        There's no need to apologize. A Wikipedia arti...\n",
       "27        Yes, because the mother of the child in the ca...\n",
       "28        \"\\nOk. But it will take a bit of work but I ca...\n",
       "29        \"== A barnstar for you! ==\\n\\n  The Real Life ...\n",
       "                                ...                        \n",
       "159541    Your absurd edits \\n\\nYour absurd edits on gre...\n",
       "159542    maybe he's got better things to do than spend ...\n",
       "159543    scrap that, it does meet criteria and its gone...\n",
       "159544                                  You could do worse.\n",
       "159545    , 7 March 2011 (UTC)\\nAre you also User:Bmatts...\n",
       "159546    \"\\n\\nHey listen don't you ever!!!! Delete my e...\n",
       "159547                       Thank you very, very much.  ·✆\n",
       "159548                          Talkback: 15 September 2012\n",
       "159549                           2005 (UTC)\\n 06:35, 31 Mar\n",
       "159550    i agree/ on another note lil wayne is a talent...\n",
       "159551    While about half the references are from BYU-I...\n",
       "159552    Prague Spring \\n\\nI think that Prague Spring d...\n",
       "159553    I see this as having been merged; undoing one ...\n",
       "159554    and i'm going to keep posting the stuff u dele...\n",
       "159555    \"\\n\\nHow come when you download that MP3 it's ...\n",
       "159556    I'll be on IRC, too, if you have a more specif...\n",
       "159557    It is my opinion that that happens to be off-t...\n",
       "159558    Please stop removing content from Wikipedia; i...\n",
       "159559    Image:Barack-obama-mother.jpg listed for delet...\n",
       "159560    \"Editing of article without Consensus & Remova...\n",
       "159561    \"\\nNo he did not, read it again (I would have ...\n",
       "159562    \"\\n Auto guides and the motoring press are not...\n",
       "159563    \"\\nplease identify what part of BLP applies be...\n",
       "159564    Catalan independentism is the social movement ...\n",
       "159565    The numbers in parentheses are the additional ...\n",
       "159566    \":::::And for the second time of asking, when ...\n",
       "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569    And it looks like it was actually you who put ...\n",
       "159570    \"\\nAnd ... I really don't think you understand...\n",
       "Name: comment_text, Length: 159571, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to lack of resources, I'm not working with the full Gutenberg \n",
    "# dataset (18 books). If you got a GPU, you can just omit the\n",
    "# ‘fileids’ parameter and all 18 books will be loaded.\n",
    "gberg_sents = gutenberg.sents(fileids=['bible-kjv.txt',\n",
    "                              'austen-emma.txt',\n",
    "                              'austen-persuasion.txt',\n",
    "                              'austen-sense.txt',\n",
    "                              'carroll-alice.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48304"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gutenberg.sents(fileids=['bible-kjv.txt',\n",
    "                                   'austen-emma.txt',\n",
    "                                   'austen-persuasion.txt',\n",
    "                                   'austen-sense.txt',\n",
    "                                   'carroll-alice.txt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25122926  0.17428908  0.37328172 -0.23726307  0.31786916 -0.26075563\n",
      "  0.21278293  0.06104695 -0.12073451 -0.3689959   0.0407492   0.12053297\n",
      " -0.06561101 -0.35064527 -0.69599712  0.06961998 -0.31599578  0.1723536\n",
      "  0.14111327  0.28670943  0.59804076 -0.48036432  0.19795424  0.074933\n",
      "  0.18414475  0.19647351  0.25440809 -0.62476718  0.13835272 -0.18230218\n",
      "  0.17891483 -0.1356931  -0.4588989   0.01018009  0.13443428 -0.0643861\n",
      " -0.09097768 -0.02164844 -0.17421161  0.07812758 -0.45156324  0.08915137\n",
      " -0.03985971  0.00921162 -0.23890261  0.13000831 -0.35392186 -0.34649539\n",
      "  0.20109813 -0.4008998   0.00700824  0.44875327 -0.01705858 -0.36711225\n",
      "  0.02937408 -0.31816766  0.28226224  0.02640702  0.3597596   0.10544787\n",
      " -0.34185138  0.24149567 -0.42596206 -0.31537178]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# size = 64, dimensions\n",
    "# sg = 1, use Skip-Gram. If zero, it will use CBOW\n",
    "# window = 10, context words (10 to the left and 10 to the right)\n",
    "# min_count = 5, ignore words with frequency lower than that\n",
    "# seed = 42, the answer to the universe, life and everything.\n",
    "# workers = 2, number of worker threads.\n",
    "model = Word2Vec(sentences=gberg_sents, size=64, sg=1,\n",
    "                 window=10, min_count=5, seed=42,\n",
    "                 workers=2)\n",
    "# Shows the coordinates of the word ‘house’ in the vector space.\n",
    "print(model['house'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'place', 0.6702732443809509), (u'courts', 0.6675680875778198), (u'repair', 0.6504998803138733), (u'chamberlain', 0.6439875960350037), (u'building', 0.6105853319168091), (u'breaches', 0.6053113341331482), (u'chamber', 0.6050419211387634), (u'city', 0.6017730832099915), (u'custody', 0.6002742052078247), (u'birthday', 0.5964493155479431)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "print(model.most_similar('house'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6702731839534064"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similarity('house','place')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
