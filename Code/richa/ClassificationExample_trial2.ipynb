{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path ='../Datasets/rawData/'\n",
    "training_data = pd.read_csv(path + 'train.csv'.format(1))\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "X = training_data.comment_text[:50000]\n",
    "y = training_data.toxic[:50000]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500,)\n",
      "(12500,)\n",
      "(37500,)\n",
      "(12500,)\n"
     ]
    }
   ],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26247            Yes that was it. I've just found out that\n",
       "35067    Bob Hope \\nI can't imagine your reasons. Its c...\n",
       "34590    \"\\n\\nDid you know? was updated. On 23 May, 200...\n",
       "16668    Thanks, Alex. If you think you can come up wit...\n",
       "12196    \"== Expand ==\\nCould somebody with adequate kn...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the vectorizer with default parameters\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<37500x79219 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1639887 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document-term matrix\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12500x79219 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 519720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Naive Baye's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.3 ms, sys: 3.33 ms, total: 28.6 ms\n",
      "Wall time: 28 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94592"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11125,   123],\n",
       "       [  553,   699]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33694    yo yo wats up wat cha doin yawljames cook was ...\n",
       "1613                      I smell like octopus poo and wee\n",
       "22568    Eurm\\nI thought you were sick! How did you sud...\n",
       "16365                    Hi girlie, you miss the turd doc?\n",
       "32967    OK, I've proven his notability, go check it ou...\n",
       "6280     \" \\n\\nGet a life3 you faggit 4 lyfe. I asked u...\n",
       "48530    I can only pray you're less of a judgmental hu...\n",
       "13518                     I am in utter disgust right now.\n",
       "38259    \"\\nThat's my darling Keeper. He grins like a b...\n",
       "9312     Yo\\n\\nYo man, you'll pick things up...read gui...\n",
       "1325     Uh oh, somebodies got internet muscles.99.235....\n",
       "37087    Master Bates \\n\\nMaster Bates, Master Bates, s...\n",
       "14097                 Death\\n\\nMan I'd kill for a cookie..\n",
       "1827     Red links\\nThe following red links have been e...\n",
       "44540    \"\\n\\n A what?!?!?! \\n\\n\"\"Crowley is a vegetari...\n",
       "48807    Dick Scanlan 4 lyfe \\n\\nAren't you a little yo...\n",
       "12314    Shame! HAHAHAHA! Yeah, i do. Whoopsie, that's ...\n",
       "48417    Pathetic little tosser. Get a real life instea...\n",
       "42030    nangparbat ==\\njust to let you know this aint ...\n",
       "24883    Like I said: Vacuous drivel and patent nonsens...\n",
       "44619             hello marky boy emilie loves your work<3\n",
       "21120    Get a life and quit stalking me. You admin clo...\n",
       "28098    Cunt Editing \\n\\nYou should be added to the li...\n",
       "16673    I'm sorry but hes done pissed me off. Anyway d...\n",
       "31076                            ya mate. Do ya wanna beer\n",
       "21203    Are you a Jew \\n\\nAre you a Jew? Don't take wh...\n",
       "12616    Stopped being funny? \\n\\nIt never stops being ...\n",
       "49806                          jesus christ get a life man\n",
       "39735                         I Love to eat rectal yoghurt\n",
       "31678    cowboy \\n\\nyour quite the cowboy admin kungfua...\n",
       "                               ...                        \n",
       "33151    Do what you want, but you'll never get rid of ...\n",
       "47785                   Bollocks to you too.149.254.183.53\n",
       "25940       Awww, my deepest appologies, here's a Kleenex.\n",
       "37530       why \\n\\nWhy don't you get a life? 80.192.32.85\n",
       "728      AMBER+TAYLOR FOREVER \\n\\nAMBER + TAYLOR FOREVE...\n",
       "8913     Typical Arab imperialist. Aren't you tired of ...\n",
       "16728                Nuisance to Cres? Never. 87.122.7.210\n",
       "14051                          Why do you hate him or her?\n",
       "34608                              \"\\nUh huh. ;-)  (//c) \"\n",
       "33996      Dark Lord Farley is well known for Hilter lover\n",
       "27994    testified \\n\\nALBUM 3\\n\\n1.i showed ya \\n2.mak...\n",
       "30256    \"\\n\\nIt's \"\"HAMMER TIME!\"\" ohh! 173.97.227.106  \"\n",
       "10471            Unanimity is Gangtuhhhh!! fo sho babyy x]\n",
       "49570    Gee Wizz \\nGeeze whizz cheese whizz, thanks fo...\n",
       "18992    This is further proof of Wikipedia's rampant J...\n",
       "28843    STOP!! \\n\\nmaybe i will stop vandelizin if u s...\n",
       "34538      leonard leopard leotard lemur leopard aLLigator\n",
       "31975    just stoppin by to say hi to all my buddies 13...\n",
       "10698    HELLO\\n\\nmy name you already know i would like...\n",
       "4111     \"\\n\\n Ahem, wtf are u talking about sire? I do...\n",
       "6270     Aggie Pool \\nPool/Spa maintenance. Cleaning, C...\n",
       "14370                            LULZ \\n\\nHAHAHAHAHAHA ==>\n",
       "43253                      SO YOUR BANNING ME FOREVER NOW?\n",
       "34995    hahaha my name is danielle nicole meyer and i ...\n",
       "19818         User:Adamkey / Joel Osteen / Lakewood Church\n",
       "2295      Jon is so smart.  S M R T!  Smart, smart, smart!\n",
       "35926                         RE: your head page...!\\nLOL!\n",
       "22565    Agnes Nitt \\nI respect what you said about Agn...\n",
       "44941    OI \\n\\nI WROTE GOOD COMMENTS!!! PMG LIEK WTF E...\n",
       "38446    If he's your friend, then why are you outing h...\n",
       "Name: comment_text, Length: 123, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24290    Vandalism is when you come along and delete va...\n",
       "15073    I have never once seen a tangible benefit from...\n",
       "14716    \"\\n\\n==SUSPICIOUS MASS EDITS-IS ANY ADMINISTRA...\n",
       "11751    Wow. A snide rude response from Xeworlebi. The...\n",
       "23082    You've got to be kidding me! \\n\\nPlease stop p...\n",
       "43113    I am also issuing YOU a citation for uncivil c...\n",
       "29703    Weak \\n\\nI sense much weakness. If there were ...\n",
       "19074    Once\\nThe song is due to chart at #1 in the UK...\n",
       "14962    \"\\nI feel bad for you actually.  You sit aroun...\n",
       "7348     You know what, this is bullshit.  Tried to do ...\n",
       "7017     \"Propol]] drew first\\nblood . Well, It gets pe...\n",
       "39590    the book is dumb \\n\\nthis book is so dumb how ...\n",
       "2015     I know that's not mature. And anyway, that was...\n",
       "10903    Playing god again==\\nBut time the deletion naz...\n",
       "40318    \"\\n\\nYou're an idiot per usual, but I'll oblig...\n",
       "722      Don't peddle your crap please.  Hate to see an...\n",
       "42216    You are insane. What is wrong with writing an ...\n",
       "48811                     ANYBODY, YOU WERE HARRASSING ME!\n",
       "38972    Transsexual \\n\\nI saw you added a transsexual ...\n",
       "9345     \"Obama is NOT \"\"African American\"\" you jackass...\n",
       "16600    What a shame (and how slightly bizarre) that j...\n",
       "21658                          Delete the page and shut up\n",
       "19243    \"\\n\\nYou know what? Forget about it, I'm going...\n",
       "20783    \"\\n\\nI've got to say, I've read you \"\"pacafist...\n",
       "21679    Then this will never be a neutral article, bec...\n",
       "931      Why are you changing the SOMALI PEOPLE WIKI???...\n",
       "37722    Dear anonymus user/or ' sockpuppet!\\nI do not ...\n",
       "37756    Who think you are ????  You the worst offender...\n",
       "23936    Xerces1492, thank you for making it clear that...\n",
       "33935    \"WARNING: MrZaius has a hard-on for the term \"...\n",
       "                               ...                        \n",
       "44321    \"\\n\\nHow dare you call ME the vandal or a Yank...\n",
       "6776     Blocking THREAT on 2012 page \\n\\nDo they get t...\n",
       "46455    \"\\n\\nDear THE HYBRID,\\nYou are what we in my f...\n",
       "698      I did not intend to be disruptive, I was genui...\n",
       "33882    VAndalism? \\n\\nHere, cuntmould. What the devil...\n",
       "42164    Ah come on. Don't bite the newcomer! Besides, ...\n",
       "35203    \"\\n\\nKeep quite you dumb ass, the Wiki guideli...\n",
       "31627    Awwwwwww, did I hit a little too close to home...\n",
       "46233    You are such an ignorant piece of refuse. You ...\n",
       "37454    I will **** you. \\n\\nYou mess with my boy, you...\n",
       "24564    \"\\n\\nThem ranting and raving at you would not ...\n",
       "27096    BREAKING NEWS!!!! \\n\\nARANEA MORTEM DIES IN A ...\n",
       "40929    Please stop wasting everybody's time and visit...\n",
       "12942    who are you \\n\\nto decide whether an edit i ma...\n",
       "10780            135.23.145.164 NEEDS TO GOE DIE IN A HOLE\n",
       "49673    Pgagnon999 has used a sock puppet to remove ci...\n",
       "9747     Not spam \\n\\nMy edit was not spam. Know why? B...\n",
       "9795     \"\\n\\nThe brit cover may be bloody awful, but y...\n",
       "17478    \" the verifibility policy. I don't know. 13 ot...\n",
       "38670    \"\\nare  you a troll? why are you accusing me t...\n",
       "18854    \"\\nplease do not interact with me. do not leav...\n",
       "12256    What are your motivations for Vandalizing arti...\n",
       "15452    I'm not  to believe for a second I could go un...\n",
       "1393     You Need To Stop. \\n\\nWhat difference does it ...\n",
       "33227    Eagle, he's just a POV pusher. He was trying t...\n",
       "41323    \"\\n\\n You are an idiot \\n You are an idiot.\\n ...\n",
       "10384    And next time, actually first create the votin...\n",
       "3365     and for the capitalize thing actually its not ...\n",
       "45312    Ummmm.... In case your Communist, Nazi super l...\n",
       "20663    You're an ass. That was not a clip of the real...\n",
       "Name: comment_text, Length: 553, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false negatives\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"and for the capitalize thing actually its not bad grammer if your using it in titles... You need a lesson from your Teacher Matt Stiker... Lol J/k ... But Seriously though if me calling other people gay offends you... you have to be a total nerd in real life that can't take being called names... oh well i feel sorry for you... wikipedia is probably the most action you get besides your creeper sites you visit...\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example false negative\n",
    "X_test[3365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.59872554e-04, 2.00115442e-04, 1.05064763e-19, ...,\n",
       "       1.29987859e-27, 3.54429225e-11, 2.56761244e-04])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities for X_test_dtm (poorly calibrated)\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8896817013120403"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate AUC\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
